{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1TiZJkHuJAz"
      },
      "source": [
        "# **Clonazione repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mblA72IGuWTS",
        "outputId": "6eaa8a35-9db8-4694-b30b-5e70a84d274a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'seaborn-data'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 208 (delta 48), reused 44 (delta 39), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (208/208), 7.29 MiB | 21.77 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "/content/seaborn-data\n"
          ]
        }
      ],
      "source": [
        "!rm -rf seaborn-data\n",
        "!git clone https://github.com/mwaskom/seaborn-data.git\n",
        "%cd seaborn-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ptXtZrucMx"
      },
      "source": [
        "# **Importazione librerie**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WHHlktpucSi"
      },
      "outputs": [],
      "source": [
        "# Importa librerie\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iluAGyO9u3Ay"
      },
      "source": [
        "## **Lettura e pulizia del dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8vuXiGFFu_TZ",
        "outputId": "031cf954-1fd1-4330-8462-b78ff4645b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Caricamento del dataset...\n",
            "Dimensioni iniziali del dataset: (344, 7)\n",
            "Dimensioni dopo la rimozione dei valori mancanti: (333, 7)\n"
          ]
        }
      ],
      "source": [
        "# Leggi il dataset\n",
        "print(\"\\n\\n\\nCaricamento del dataset...\")\n",
        "df = pd.read_csv(\"penguins.csv\")\n",
        "print(f\"Dimensioni iniziali del dataset: {df.shape}\")\n",
        "\n",
        "# Rimuovi righe con valori NaN nelle colonne specifiche\n",
        "df_cleaned = df.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']).copy()\n",
        "\n",
        "print(f\"Dimensioni dopo la rimozione dei valori mancanti: {df_cleaned.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9sCtbUXYVsC"
      },
      "source": [
        "# **Selezione delle features da utilizzare ell'addestramento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V2z9LrfdlG1"
      },
      "outputs": [],
      "source": [
        "# Seleziona le caratteristiche e normalizza\n",
        "features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']  # Puoi aggiungere o modificare le caratteristiche\n",
        "X = df_cleaned[features]\n",
        "Y = df_cleaned['sex']\n",
        "print(f\"Caratteristiche selezionate: {features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d5N81KJfTi7"
      },
      "source": [
        "# ** Normalizzazione dei dati**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kunL1yyHfT5a"
      },
      "outputs": [],
      "source": [
        "# Normalizza i dati\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Caratteristiche normalizzate.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCXC_dxvfvJj"
      },
      "source": [
        "# **Suddivisione del dataset in training e test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRNpz8g9gUmY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "collapsed": true,
        "id": "FMeQejviqNKl",
        "outputId": "1800b474-64a4-46c6-a2f4-51409f701513"
      },
      "outputs": [],
      "source": [
        "# Suddivisione del dataset in training e test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
        "print(f\"Set di addestramento: {X_train.shape}, Set di test: {X_test.shape}\")\n",
        "\n",
        "# Test con diverse quantità di vicini\n",
        "k_values = range(1, 21)\n",
        "accuracy_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, Y_train)\n",
        "    y_pred_k = knn.predict(X_test)\n",
        "    accuracy_scores.append(accuracy_score(Y_test, y_pred_k))\n",
        "\n",
        "# Visualizza il grafico delle accuratezze\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, accuracy_scores, marker='o')\n",
        "\n",
        "# Aggiungi righe tratteggiate per ogni punto del grafico\n",
        "for k, accuracy in zip(k_values, accuracy_scores):\n",
        "    plt.axvline(x=k, color='lightgray', linestyle='-', alpha=0.15)  # Linea verticale per ogni punto\n",
        "\n",
        "# Imposta l'intervallo dei valori dell'asse x a 1 (di default k_values è già in incrementi di 1)\n",
        "plt.xticks(k_values)  # Imposta i valori dell'asse x a 1 per ogni k nel range\n",
        "\n",
        "plt.xlabel('Numero di vicini (k)')\n",
        "plt.ylabel('Accuratezza')\n",
        "plt.title('Valutazione del KNN con diversi valori di k')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "time.sleep(1)\n",
        "\n",
        "# Numero di vicini (k) per KNN\n",
        "k_neighbors = int(input(\"Inserisci il numero di vicini (k) per KNN: \"))\n",
        "\n",
        "# Applica KNN\n",
        "print(f\"Eseguo KNN con k={k_neighbors}...\")\n",
        "knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "knn.fit(X_train, Y_train)\n",
        "#----------------------------------------------------------------------\n",
        "# Fai previsioni\n",
        "Y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calcola e mostra la matrice di confusione\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=df_cleaned['sex'].unique())\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "\n",
        "# Calcola le metriche di valutazione\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Aggiungi le etichette originali per il training e le predizioni per il test\n",
        "X_full = np.vstack((X_train, X_test))  # Combina i dati di addestramento e test\n",
        "Y_full = np.concatenate((Y_train, Y_pred))  # Etichette: originali per training, predette per test\n",
        "is_test = np.array([0] * len(Y_train) + [1] * len(Y_pred))  # Flag per distinguere test e training\n",
        "\n",
        "# Visualizza tutti i dati\n",
        "plt.figure(figsize=(6, 6))\n",
        "scatter_plot = sns.scatterplot(\n",
        "    x=X_full[:, 0],  # Lunghezza del becco\n",
        "    y=X_full[:, 1],  # Massa corporea\n",
        "    hue=Y_full,  # Etichette: originali o predette\n",
        "    style=is_test,  # Differenzia test e training\n",
        "    palette='Set1',\n",
        "    s=50\n",
        ")\n",
        "plt.title('Classificazione dei Pinguini con KNN')\n",
        "plt.xlabel('Lunghezza del Becco (mm)')\n",
        "plt.ylabel('Massa Corporea (g)')\n",
        "\n",
        "# Personalizza la legenda per i punti Test e Train\n",
        "handles, labels = scatter_plot.get_legend_handles_labels()\n",
        "new_labels = labels[:len(set(Y_full))] + ['Train', 'Test']  # Etichette personalizzate\n",
        "plt.legend(handles, new_labels, title='Legenda', loc='upper right')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
